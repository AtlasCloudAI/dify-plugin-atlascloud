model: qwen/qwen3-8b
label:
  zh_Hans: Qwen3 8B
  en_US: Qwen3 8B
model_type: llm
features:
  - tool-call
model_properties:
  mode: chat
  context_size: 128000
parameter_rules:
  - name: temperature
    use_template: temperature
    type: float
    default: 0.7
    min: 0.0
    max: 2.0
    help:
      zh_Hans: 控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。
      en_US: Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is.
  - name: max_tokens
    use_template: max_tokens
    type: int
    default: 4096
    min: 1
    max: 32768
    help:
      zh_Hans: 指定生成结果长度的上限。如果生成结果截断，可以调大该参数。
      en_US: Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter.
  - name: top_p
    use_template: top_p
    type: float
    default: 0.8
    min: 0.01
    max: 1.00
    help:
      zh_Hans: 控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。
      en_US: Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature.
  - name: presence_penalty
    use_template: presence_penalty
    type: float
    default: 0
    min: 0.0
    max: 2.0
    help:
      zh_Hans: 根据新标记是否出现在文本中对其进行惩罚，增加谈论新主题的可能性。
      en_US: Penalize new tokens based on whether they appear in the text so far, increasing the likelihood of talking about new topics.
  - name: response_format
    use_template: response_format
pricing:
  input: "0.04"
  output: "0.12"
  unit: "0.000001"
  currency: USD
